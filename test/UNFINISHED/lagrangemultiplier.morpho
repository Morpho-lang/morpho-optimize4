// Test PenaltyAdapter and PenaltyController 

import optimize4

var _OptUnConsErr = Error("OpUncons", "Problem appears to be unconstrained.")

class LagrangeMultiplierAdapter is OptimizationAdapter {
  init(adapter) {
    self.adapter = adapter
    self.nconstraints = self.constraintVector().count() 
    self.lambda = Matrix(self.nconstraints)
  }

  set(x) { // Get parameters, stripping off lagrange multipliers
    var n = x.count()
    var nvars = n - self.nconstraints
    self.adapter.set(x[0...nvars,0])
    self.lambda = x[nvars...n,0] // Store lagrange multipliers on this adapter
  }

  get() { // Get parameters, joining real parameters with lagrange multipliers
    var x = self.adapter.get()
    return Matrix([[x], [self.lambda]]) 
  }

  lagrangemultipliers() {
    return self.lambda 
  }

  _checkineq(c) {
    var M = self.adapter.countConstraints()
    var Meq = self.adapter.countEqualityConstraints()
    for (k in Meq...M) {
      if (c[k]>0) c[k]=0
    }
  }

  constraintVector() {
    var v = self.adapter.constraintValue()

    if (v) {
      v = Matrix(v)
      self._checkineq(v)
    } else _OptUnConsErr.warning() 

    return v 
  }

  value() { // Lagrangian = f + lambda_i c_i
    var f = self.adapter.value() 
    var c = self.constraintVector()

    return f + self.lambda.inner(c)  
  }

  gradient() { // Gradient of Lagrangian is [ df + lambda_i dc_i , c_i] 
    var grad = self.adapter.gradient()

    var c = self.constraintVector()
    var cgrad = self.adapter.constraintGradient()

    for (cg,k in cgrad) grad += self.lambda[k]*cg

    return Matrix([[grad],[c]]) 
  } 

  hessian() { // Hessian of Lagrangian is the kkt matrix 
    var h = self.adapter.hessian()    

    var chess = self.adapter.constraintHessian() 
    for (ch,k in chess) h += self.lambda[k]*ch

    var cg = self.adapter.constraintGradient()
    var C = Matrix([cg])

    return Matrix([[h, C],[C.transpose(), 0]])
  }
}

fn func(x, y, z) {
  return (x+2)^2 + 0.5*(y-2)^4 + 2*(z-2)^2
}

fn g(x, y, z) {
  return x + y - 1
}

fn h(x, y, z) {
  return x
}

var start = Matrix([1,1,1])

var adapt = FunctionAdapter(func, start=start, constraints = [g, h], equalitycount=1)

var ladapt = LagrangeMultiplierAdapter(adapt) 

print ladapt.value() 

print ladapt.gradient()

print ladapt.constraintGradient()

//var control = NewtonController(ladapt)
//control.optimize(10)
//print ladapt.get()
